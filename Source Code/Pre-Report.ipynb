{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring The Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> <ul>\n",
    "    <li>Chúng ta sử Dataset này để xây dựng một mô hình dự đoán bằng thuật toán Decision Tree bằng MLLib của Spark\n",
    "    và được thực hiện bằng Pyspark của Python.\n",
    "    </li>\n",
    "    <li>Black fridat là một bộ dữ liệu được thu thập từ một cửa hàng bán lẻ về các giao dịch trong ngày blackfriday.Có thể download dataset từ https://www.kaggle.com/sdolezel/black-friday\n",
    "    </li>\n",
    "    <li>\n",
    "        Chúng tôi sử dụng thuật toán Decision Tree của nhóm thuật toán Regression để thực hiện việc dự đoán biến liên tục Purchase dự trên các biến phân loại còn lại của tập dữ liệu như Product_ID,Occupation,Gender,...\n",
    "    </li>\n",
    "    </ul>\n",
    "    \n",
    "</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 - Load dataset \n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bạn thay đổi đường dẫn tương ứng với đường dẫn tới thư mục chứa dataset trên máy của bạn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User_ID: integer (nullable = true)\n",
      " |-- Product_ID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Occupation: integer (nullable = true)\n",
      " |-- City_Category: string (nullable = true)\n",
      " |-- Stay_In_Current_City_Years: string (nullable = true)\n",
      " |-- Marital_Status: integer (nullable = true)\n",
      " |-- Product_Category_1: integer (nullable = true)\n",
      " |-- Product_Category_2: integer (nullable = true)\n",
      " |-- Product_Category_3: integer (nullable = true)\n",
      " |-- Purchase: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Project-Bigdata\").getOrCreate()\n",
    "df = spark.read.csv('../dataset/BlackFriday.csv',header=True,inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sử dụng phương thức .show( ) để hiển thị 20 rows đầu của dataset (Đối với phương thức này rất khó để bạn quát sát được đối với dataset có nhiều biến.Quan sát kết quả bạn sẽ thấy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|User_ID|Product_ID|Gender|  Age|Occupation|City_Category|Stay_In_Current_City_Years|Marital_Status|Product_Category_1|Product_Category_2|Product_Category_3|Purchase|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "|1000001| P00069042|     F| 0-17|        10|            A|                         2|             0|                 3|              null|              null|    8370|\n",
      "|1000001| P00248942|     F| 0-17|        10|            A|                         2|             0|                 1|                 6|                14|   15200|\n",
      "|1000001| P00087842|     F| 0-17|        10|            A|                         2|             0|                12|              null|              null|    1422|\n",
      "|1000001| P00085442|     F| 0-17|        10|            A|                         2|             0|                12|                14|              null|    1057|\n",
      "|1000002| P00285442|     M|  55+|        16|            C|                        4+|             0|                 8|              null|              null|    7969|\n",
      "|1000003| P00193542|     M|26-35|        15|            A|                         3|             0|                 1|                 2|              null|   15227|\n",
      "|1000004| P00184942|     M|46-50|         7|            B|                         2|             1|                 1|                 8|                17|   19215|\n",
      "|1000004| P00346142|     M|46-50|         7|            B|                         2|             1|                 1|                15|              null|   15854|\n",
      "|1000004|  P0097242|     M|46-50|         7|            B|                         2|             1|                 1|                16|              null|   15686|\n",
      "|1000005| P00274942|     M|26-35|        20|            A|                         1|             1|                 8|              null|              null|    7871|\n",
      "|1000005| P00251242|     M|26-35|        20|            A|                         1|             1|                 5|                11|              null|    5254|\n",
      "|1000005| P00014542|     M|26-35|        20|            A|                         1|             1|                 8|              null|              null|    3957|\n",
      "|1000005| P00031342|     M|26-35|        20|            A|                         1|             1|                 8|              null|              null|    6073|\n",
      "|1000005| P00145042|     M|26-35|        20|            A|                         1|             1|                 1|                 2|                 5|   15665|\n",
      "|1000006| P00231342|     F|51-55|         9|            A|                         1|             0|                 5|                 8|                14|    5378|\n",
      "|1000006| P00190242|     F|51-55|         9|            A|                         1|             0|                 4|                 5|              null|    2079|\n",
      "|1000006|  P0096642|     F|51-55|         9|            A|                         1|             0|                 2|                 3|                 4|   13055|\n",
      "|1000006| P00058442|     F|51-55|         9|            A|                         1|             0|                 5|                14|              null|    8851|\n",
      "|1000007| P00036842|     M|36-45|         1|            B|                         1|             1|                 1|                14|                16|   11788|\n",
      "|1000008| P00249542|     M|26-35|        12|            C|                        4+|             1|                 1|                 5|                15|   19614|\n",
      "+-------+----------+------+-----+----------+-------------+--------------------------+--------------+------------------+------------------+------------------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quan sát dataset ta thấy :\n",
    "#### Dataset gồm có 12 biến : \n",
    "#### Trong đó các biến input : User_ID, Product_ID, Gender, Age,Occupation, City_Category, Stay_In_Current_City_Years, Marital_Status, Product_Category_1, Product_Category_2, Product_Category_3\n",
    "#### Biến output là : Purchase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quan sát dữ liệu của 5 dòng đầu tiên trong dataset.Sử dụng Pandas Datafram có thể nhìn rõ hơn là Spark Dataframe.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User_ID</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_ID</th>\n",
       "      <td>P00069042</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>P00285442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0-17</td>\n",
       "      <td>0-17</td>\n",
       "      <td>0-17</td>\n",
       "      <td>0-17</td>\n",
       "      <td>55+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Occupation</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City_Category</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marital_Status</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_Category_1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_Category_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_Category_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purchase</th>\n",
       "      <td>8370</td>\n",
       "      <td>15200</td>\n",
       "      <td>1422</td>\n",
       "      <td>1057</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0          1          2          3  \\\n",
       "User_ID                       1000001    1000001    1000001    1000001   \n",
       "Product_ID                  P00069042  P00248942  P00087842  P00085442   \n",
       "Gender                              F          F          F          F   \n",
       "Age                              0-17       0-17       0-17       0-17   \n",
       "Occupation                         10         10         10         10   \n",
       "City_Category                       A          A          A          A   \n",
       "Stay_In_Current_City_Years          2          2          2          2   \n",
       "Marital_Status                      0          0          0          0   \n",
       "Product_Category_1                  3          1         12         12   \n",
       "Product_Category_2                NaN          6        NaN         14   \n",
       "Product_Category_3                NaN         14        NaN        NaN   \n",
       "Purchase                         8370      15200       1422       1057   \n",
       "\n",
       "                                    4  \n",
       "User_ID                       1000002  \n",
       "Product_ID                  P00285442  \n",
       "Gender                              M  \n",
       "Age                               55+  \n",
       "Occupation                         16  \n",
       "City_Category                       C  \n",
       "Stay_In_Current_City_Years         4+  \n",
       "Marital_Status                      0  \n",
       "Product_Category_1                  8  \n",
       "Product_Category_2                NaN  \n",
       "Product_Category_3                NaN  \n",
       "Purchase                         7969  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(df.take(5), columns=df.columns).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 - Kiểm tra giá trị thiếu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Chúng tôi xây dựng một hàm để kiểm tra số lượng giá trị thiếu của mỗi cột và trả ra số lượng giá trị thiếu đó</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col, count, isnan, lit, sum\n",
    "def count_null(c, nan_as_null=False):\n",
    "    \"\"\"Use conversion between boolean and integer\n",
    "    - False -> 0\n",
    "    - True ->  1\n",
    "    \"\"\"\n",
    "    pred = col(c).isNull() & (isnan(c) if nan_as_null else lit(True))\n",
    "    return sum(pred.cast(\"integer\")).alias(c)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Ta sử dụng hàm agg() để thực hiện việc tính toán của hàm count_null (đếm giá trị thiếu trên dataset theo từng cột) và sử dụng toPandas() để hiển thị kết quả</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Product_ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Occupation</th>\n",
       "      <th>City_Category</th>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Product_Category_1</th>\n",
       "      <th>Product_Category_2</th>\n",
       "      <th>Product_Category_3</th>\n",
       "      <th>Purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166986</td>\n",
       "      <td>373299</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID  Product_ID  Gender  Age  Occupation  City_Category  \\\n",
       "0        0           0       0    0           0              0   \n",
       "\n",
       "   Stay_In_Current_City_Years  Marital_Status  Product_Category_1  \\\n",
       "0                           0               0                   0   \n",
       "\n",
       "   Product_Category_2  Product_Category_3  Purchase  \n",
       "0              166986              373299         0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.agg(*[count_null(c) for c in df.columns]).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Quan sát ta thấy có 2 cột có giá trị thiếu đó là Product_Category_2 và Product_Category_3 lần lượt là 166986 và 373299</b> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ta xử lí giá trị thiếu này bằng cách sử dụng phương Imputer của MLlib để điền vào các vị trí null của tập dữ liệu.Imputer sẽ thực hiện tính giá trị trung bình của cột đầu vào và điền vào các vị trí null của cột đó.\n",
    "#### Đối với phương thức này yêu cầu các đầu vào phải có kiểu giá trị là float nên ta sẽ ép kiểu giá trị 2 cột này sang float.\n",
    "#### Quan sát code bên dưới"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import FloatType\n",
    "df = df.withColumn(\"Product_Category_2\", df[\"Product_Category_2\"].cast(FloatType()))\n",
    "df = df.withColumn(\"Product_Category_3\", df[\"Product_Category_3\"].cast(FloatType()))\n",
    "from pyspark.ml.feature import Imputer\n",
    "imputer = Imputer(strategy=\"median\",inputCols=[\"Product_Category_2\", \"Product_Category_3\"], outputCols=[\"Out_Product_Category_2\", \"Out_Product_Category_3\"])\n",
    "df = imputer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Như vậy là ta đã có được 2 cột mới được tạo ra và thêm vào dataset ban đầu với tên như đã khởi tạo là Out_Product_Category_2 ,Out_Product_Category_3 ứng với 2 cột ban đầu là Product_Category_2 và Product_Category_3.Tuy nhiên 2 cột mới này đã được xử lý giá trị thiếu.\n",
    "### Quan sát lại dataset để kiểm tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>User_ID</th>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1000002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_ID</th>\n",
       "      <td>P00069042</td>\n",
       "      <td>P00248942</td>\n",
       "      <td>P00087842</td>\n",
       "      <td>P00085442</td>\n",
       "      <td>P00285442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gender</th>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>F</td>\n",
       "      <td>M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>0-17</td>\n",
       "      <td>0-17</td>\n",
       "      <td>0-17</td>\n",
       "      <td>0-17</td>\n",
       "      <td>55+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Occupation</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City_Category</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stay_In_Current_City_Years</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marital_Status</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_Category_1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_Category_2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_Category_3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purchase</th>\n",
       "      <td>8370</td>\n",
       "      <td>15200</td>\n",
       "      <td>1422</td>\n",
       "      <td>1057</td>\n",
       "      <td>7969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Out_Product_Category_2</th>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Out_Product_Category_3</th>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    0          1          2          3  \\\n",
       "User_ID                       1000001    1000001    1000001    1000001   \n",
       "Product_ID                  P00069042  P00248942  P00087842  P00085442   \n",
       "Gender                              F          F          F          F   \n",
       "Age                              0-17       0-17       0-17       0-17   \n",
       "Occupation                         10         10         10         10   \n",
       "City_Category                       A          A          A          A   \n",
       "Stay_In_Current_City_Years          2          2          2          2   \n",
       "Marital_Status                      0          0          0          0   \n",
       "Product_Category_1                  3          1         12         12   \n",
       "Product_Category_2                NaN          6        NaN         14   \n",
       "Product_Category_3                NaN         14        NaN        NaN   \n",
       "Purchase                         8370      15200       1422       1057   \n",
       "Out_Product_Category_2              9          6          9         14   \n",
       "Out_Product_Category_3             14         14         14         14   \n",
       "\n",
       "                                    4  \n",
       "User_ID                       1000002  \n",
       "Product_ID                  P00285442  \n",
       "Gender                              M  \n",
       "Age                               55+  \n",
       "Occupation                         16  \n",
       "City_Category                       C  \n",
       "Stay_In_Current_City_Years         4+  \n",
       "Marital_Status                      0  \n",
       "Product_Category_1                  8  \n",
       "Product_Category_2                NaN  \n",
       "Product_Category_3                NaN  \n",
       "Purchase                         7969  \n",
       "Out_Product_Category_2              9  \n",
       "Out_Product_Category_3             14  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df.take(5), columns=df.columns).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 - Tóm tắt các số liệu thống kê của các biến kiểu số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_ID</th>\n",
       "      <td>537577</td>\n",
       "      <td>1002991.8470284257</td>\n",
       "      <td>1714.3926953612104</td>\n",
       "      <td>1000001</td>\n",
       "      <td>1006040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Occupation</th>\n",
       "      <td>537577</td>\n",
       "      <td>8.082710011775058</td>\n",
       "      <td>6.5241197699355435</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marital_Status</th>\n",
       "      <td>537577</td>\n",
       "      <td>0.4087972513705013</td>\n",
       "      <td>0.49161215222967697</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product_Category_1</th>\n",
       "      <td>537577</td>\n",
       "      <td>5.295546498455105</td>\n",
       "      <td>3.750700949879793</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Purchase</th>\n",
       "      <td>537577</td>\n",
       "      <td>9333.859852635065</td>\n",
       "      <td>4981.022132656474</td>\n",
       "      <td>185</td>\n",
       "      <td>23961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Out_Product_Category_2</th>\n",
       "      <td>537577</td>\n",
       "      <td>9.58055125126261</td>\n",
       "      <td>4.241811529227285</td>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Out_Product_Category_3</th>\n",
       "      <td>537577</td>\n",
       "      <td>13.59351683572772</td>\n",
       "      <td>2.360842314432035</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             0                   1                    2  \\\n",
       "summary                  count                mean               stddev   \n",
       "User_ID                 537577  1002991.8470284257   1714.3926953612104   \n",
       "Occupation              537577   8.082710011775058   6.5241197699355435   \n",
       "Marital_Status          537577  0.4087972513705013  0.49161215222967697   \n",
       "Product_Category_1      537577   5.295546498455105    3.750700949879793   \n",
       "Purchase                537577   9333.859852635065    4981.022132656474   \n",
       "Out_Product_Category_2  537577    9.58055125126261    4.241811529227285   \n",
       "Out_Product_Category_3  537577   13.59351683572772    2.360842314432035   \n",
       "\n",
       "                              3        4  \n",
       "summary                     min      max  \n",
       "User_ID                 1000001  1006040  \n",
       "Occupation                    0       20  \n",
       "Marital_Status                0        1  \n",
       "Product_Category_1            1       18  \n",
       "Purchase                    185    23961  \n",
       "Out_Product_Category_2        2       18  \n",
       "Out_Product_Category_3        3       18  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "df = df.withColumn(\"Out_Product_Category_2\", df[\"Out_Product_Category_2\"].cast(IntegerType()))\n",
    "df = df.withColumn(\"Out_Product_Category_3\", df[\"Out_Product_Category_3\"].cast(IntegerType()))\n",
    "numeric_features = [t[0] for t in df.dtypes if t[1] == 'int']\n",
    "df.select(numeric_features).describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 - Xây dưng pipeline để tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tương tự như việc thực hiện phương thức xử lí giá trị thiếu bên trên, ta tiến hành xử lý các dữ liệu còn lại "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các bạn xem lại lý thuyết Pipeline , Estimator, Transformer để biết cách hoạt động và thực hiện các đối tượng này.Đoạn code bên dưới chúng tôi sử dụng các phương thức như StringIndexer ,  OneHotEncoderEstimator , VectorAssembler để xử lý các thuộc tính phân loại như 'Product_ID', 'Gender', 'Age', 'Stay_In_Current_City_Years' .Các bạn có thể tìm hiểu các phương thức đó là gì tại Document của Spark.\n",
    "### Ở đây tôi muốn thực hiện việc biến đổi các giá trị phân loại của các biến phần loại này thành các chỉ số phân loại của nó bằng phương thức StringIndexer.Sau đó sử dụng phương thức OneHotEncoderEstimator để mã hóa các giá trị vừa biến đối trên thành vector nhị phân.Và cuối cùng là chúng tôi gọp các thuộc tính phân loại đã biến đổi trên với các thuộc tính kiểu số lại thành 1 vector là lấy tên là features bằng phương thức VectorAssembler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import OneHotEncoderEstimator, StringIndexer, VectorAssembler\n",
    "categoricalColumns = ['Product_ID', 'Gender', 'Age', 'Stay_In_Current_City_Years']\n",
    "stages = []\n",
    "for categoricalCol in categoricalColumns:\n",
    "    stringIndexer = StringIndexer(inputCol = categoricalCol, outputCol = categoricalCol + 'Index')\n",
    "    encoder = OneHotEncoderEstimator(inputCols=[stringIndexer.getOutputCol()], outputCols=[categoricalCol + \"classVec\"])\n",
    "    stages += [stringIndexer, encoder]\n",
    "numericCols = ['Occupation', 'Marital_Status', 'Product_Category_1', 'Out_Product_Category_2', 'Out_Product_Category_3']\n",
    "assemblerInputs = [c + \"classVec\" for c in categoricalColumns] + numericCols\n",
    "assembler = VectorAssembler(inputCols=assemblerInputs, outputCol=\"features\")\n",
    "stages += [assembler]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các bạn có thể thấy tôi sử dụng biến stages để đại diện có các giai đoạn chúng tôi xử lý dữ liệu đã miêu tả bên trên.Cuối cùng là tôi sử dụng đối tượng Pipeline để thực hiện việc xử lý đó trên tập dữ liệu của chúng ta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- User_ID: integer (nullable = true)\n",
      " |-- Product_ID: string (nullable = true)\n",
      " |-- Gender: string (nullable = true)\n",
      " |-- Age: string (nullable = true)\n",
      " |-- Occupation: integer (nullable = true)\n",
      " |-- City_Category: string (nullable = true)\n",
      " |-- Stay_In_Current_City_Years: string (nullable = true)\n",
      " |-- Marital_Status: integer (nullable = true)\n",
      " |-- Product_Category_1: integer (nullable = true)\n",
      " |-- Product_Category_2: float (nullable = true)\n",
      " |-- Product_Category_3: float (nullable = true)\n",
      " |-- Purchase: integer (nullable = true)\n",
      " |-- Out_Product_Category_2: integer (nullable = true)\n",
      " |-- Out_Product_Category_3: integer (nullable = true)\n",
      " |-- Product_IDIndex: double (nullable = false)\n",
      " |-- Product_IDclassVec: vector (nullable = true)\n",
      " |-- GenderIndex: double (nullable = false)\n",
      " |-- GenderclassVec: vector (nullable = true)\n",
      " |-- AgeIndex: double (nullable = false)\n",
      " |-- AgeclassVec: vector (nullable = true)\n",
      " |-- Stay_In_Current_City_YearsIndex: double (nullable = false)\n",
      " |-- Stay_In_Current_City_YearsclassVec: vector (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "pipeline = Pipeline(stages = stages)\n",
    "pipelineModel = pipeline.fit(df)\n",
    "df = pipelineModel.transform(df)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IllegalArgumentException",
     "evalue": "'Field \"Purchase\" does not exist.\\nAvailable fields: Purchase_Indexer, features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mPy4JJavaError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/Spark/spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mpy4j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPy4JJavaError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Spark/spark-2.4.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/protocol.py\u001b[0m in \u001b[0;36mget_return_value\u001b[0;34m(answer, gateway_client, target_id, name)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0;34m\"An error occurred while calling {0}{1}{2}.\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                     format(target_id, \".\", name), value)\n\u001b[0m\u001b[1;32m    329\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mPy4JJavaError\u001b[0m: An error occurred while calling o849.fit.\n: java.lang.IllegalArgumentException: Field \"Purchase\" does not exist.\nAvailable fields: Purchase_Indexer, features\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:274)\n\tat org.apache.spark.sql.types.StructType$$anonfun$apply$1.apply(StructType.scala:274)\n\tat scala.collection.MapLike$class.getOrElse(MapLike.scala:128)\n\tat scala.collection.AbstractMap.getOrElse(Map.scala:59)\n\tat org.apache.spark.sql.types.StructType.apply(StructType.scala:273)\n\tat org.apache.spark.ml.feature.StringIndexerBase$class.validateAndTransformSchema(StringIndexer.scala:85)\n\tat org.apache.spark.ml.feature.StringIndexer.validateAndTransformSchema(StringIndexer.scala:109)\n\tat org.apache.spark.ml.feature.StringIndexer.transformSchema(StringIndexer.scala:152)\n\tat org.apache.spark.ml.PipelineStage.transformSchema(Pipeline.scala:74)\n\tat org.apache.spark.ml.feature.StringIndexer.fit(StringIndexer.scala:135)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n\tat sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n\tat sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n\tat java.lang.reflect.Method.invoke(Method.java:498)\n\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n\tat py4j.Gateway.invoke(Gateway.java:282)\n\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n\tat py4j.GatewayConnection.run(GatewayConnection.java:238)\n\tat java.lang.Thread.run(Thread.java:748)\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-842ac38ffdbe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpurchase\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIndexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Purchase\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moutputCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Purchase_Indexer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpurchase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Spark/spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/base.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m~/Spark/spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_copyValues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Spark/spark-2.4.4-bin-hadoop2.7/python/pyspark/ml/wrapper.py\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    290\u001b[0m         \"\"\"\n\u001b[1;32m    291\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Spark/spark-2.4.4-bin-hadoop2.7/python/lib/py4j-0.10.7-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1255\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1256\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1257\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1259\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Spark/spark-2.4.4-bin-hadoop2.7/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: 'Field \"Purchase\" does not exist.\\nAvailable fields: Purchase_Indexer, features'"
     ]
    }
   ],
   "source": [
    "purchase = StringIndexer(inputCol=\"Purchase\",outputCol=\"Purchase_Indexer\")\n",
    "df = purchase.fit(df).transform(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Các bạn quan sát bây giờ dataset của chúng ta đã có thêm những cột mới được thêm vào.Đó là các cột đã được xử lý dữ liệu và có một cột features ở cuối, đó là cột thuộc tính đã diện cho các cột còn lại đã được biến đổi thành 1 vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Purchase_Indexer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11352.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5845.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8950.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537572</th>\n",
       "      <td>3011.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537573</th>\n",
       "      <td>5194.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537574</th>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537575</th>\n",
       "      <td>138.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537576</th>\n",
       "      <td>368.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>537577 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Purchase_Indexer\n",
       "0                11352.0\n",
       "1                 2260.0\n",
       "2                 5845.0\n",
       "3                 8950.0\n",
       "4                  237.0\n",
       "...                  ...\n",
       "537572            3011.0\n",
       "537573            5194.0\n",
       "537574             134.0\n",
       "537575             138.0\n",
       "537576             368.0\n",
       "\n",
       "[537577 rows x 1 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selectedCols = ['Purchase_Indexer', 'features']\n",
    "df = df.select(selectedCols)\n",
    "##pd.DataFrame(df.take(5), columns=df.columns).transpose()\n",
    "df.select(\"Purchase_Indexer\").toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5 - Chia dataset của chúng ta thành 2 tập dữ liệu là Train và Test để tiến hành xây dựng model.\n",
    "### Chúng ta sẽ sử dụng tập Train để học model và tập Test để kiểm tra mô hình dự đoán ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset Count: 375810\n",
      "Test Dataset Count: 161767\n"
     ]
    }
   ],
   "source": [
    "train, test = df.randomSplit([0.7, 0.3], seed = 2018)\n",
    "print(\"Training Dataset Count: \" + str(train.count()))\n",
    "print(\"Test Dataset Count: \" + str(test.count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Purchase_Indexer: double (nullable = false)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6 - Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeRegressor(featuresCol = 'features',labelCol= 'Purchase_Indexer', maxDepth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = dt.fit(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7 - Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+----------------+--------------------+\n",
      "|       prediction|Purchase_Indexer|            features|\n",
      "+-----------------+----------------+--------------------+\n",
      "|1325.259488858244|             0.0|(3638,[12,3622,36...|\n",
      "|1325.259488858244|             0.0|(3638,[16,3622,36...|\n",
      "|1325.259488858244|             0.0|(3638,[77,3622,36...|\n",
      "|1325.259488858244|             0.0|(3638,[95,3622,36...|\n",
      "|1325.259488858244|             0.0|(3638,[129,3625,3...|\n",
      "+-----------------+----------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"prediction\", \"Purchase_Indexer\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8 - Đánh giá model bằng các độ đo "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ RMSE $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root Mean Squared Error (RMSE) on test data = 2120.77 \n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"Purchase_Indexer\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(\"Root Mean Squared Error (RMSE) on test data = %g \" % rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ R^2$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared (R2)  = 0.61293 \n"
     ]
    }
   ],
   "source": [
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"Purchase_Indexer\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R-squared (R2)  = %g \" % r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
